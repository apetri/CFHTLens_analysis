%\documentclass[useAMS, usenatbib,usegraphicx,letter]{mn2e}
%\documentclass[11pt]{article}
\documentclass[reprint,aps,prd,superscriptaddress,showkeys]{revtex4-1}
\usepackage{epsfig,amsmath,natbib}

\usepackage{aas_macros}
\usepackage{amssymb}
 \usepackage{amsmath}
 \usepackage{dsfont}
 \usepackage{hyperref}
 \usepackage{color}
\hypersetup{
	colorlinks=false,
	citecolor=green
}
% \usepackage{graphicx}
% \usepackage{epstopdf}
% \usepackage{natbib}

\begin{document}

\title{CFHTLens Weak Lensing Emulator and Cosmological Constraints from the Minkowski Functionals and Moments}

\author{Andrea Petri}
\email{apetri@phys.columbia.edu}
\affiliation{Department of Physics, Columbia University, New York, NY 10027, USA}
\affiliation{Physics Department, Brookhaven National Laboratory, Upton, NY 11973, USA}

\author{Jia Liu}
\affiliation{Department of Astronomy, Columbia University, New York, NY 10027, USA}

\author{Zolt\'an Haiman}
\affiliation{Department of Astronomy, Columbia University, New York, NY 10027, USA}

\author{Lam Hui}
\affiliation{Department of Physics, Columbia University, New York, NY 10027, USA}

\author{Jan M. Kratochvil}
\affiliation{Astrophysics and Cosmology Research Unit, University of KwaZulu-Natal, Westville, Durban 4000, South Africa}

\author{Morgan May}
\affiliation{Physics Department, Brookhaven National Laboratory, Upton, NY 11973, USA}

\date{\today}

\label{firstpage}

\begin{abstract}
Weak lensing surveys have the potential... we consider CFHTLens \citep{CFHTKilbinger,CFHTFu}
\end{abstract}

\keywords{Weak Gravitational Lensing --- Data analysis --- Methods: analytical,numerical,statistical}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%% INTRO %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
In this work...

%%%%%%%%%%%%%%%%%%%%%%%%%% DATA AND SIMULATIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data and simulations}

\subsection{CFHTLens data reduction}
\label{cfhtdatareduction}
%
The CFHTLens survey covers four sky patches of 64,23,44 and 23 deg$^2$ area, for a total of 154 deg$^2$; the publicly released data roughly consist of the creation of a galaxy catalogue using SExtractor \citep{SExtractor}, a photometric redshift estimation with a Bayesian photometric redshift code \citep{PhotoCode} and galaxy shape measurements with \textit{lensfit} \citep{cfht1,cfht2}. The cosmological parameter inferences have been obtained in \citep{CFHTKilbinger} using the two point correlation function (2PCF). We apply the following cuts to the galaxy catalogue: mask$<1$, redshift $0.2 < z < 1.3$, fitclass = 0 (which requires the object to be a galaxy) and weight $w>0$ (with larger $w$ indicating smaller shear measurement uncertainty). Applying these cuts leaves us 4.2$\times10^6$ galaxies, 124.7 deg$^2$ residual sky coverage, and average number density $n_{gal} \approx 9.3\,\mathrm{arcmin}^{-2}$. The CFHTLens galaxy catalogue provides us with the sky position $\pmb{\theta}$, the redshift $z(\pmb{\theta})$ and ellipticity $\mathbf{e}(\pmb{\theta})$ of eack galaxy, as well as the individual weight factors $w(\pmb{\theta})$ and additive and multiplicative ellipticity corrections $c(\pmb{\theta}),m(\pmb{\theta})$. Because the CFHTLenS fields are irregularly shaped, we first divide them into 13 squares (subfields) to match the shape and $\approx12$ deg$^2$ size of our simulated maps; these square subfield maps are pixelized according to a Gaussian gridding procedure
\begin{equation}
\bar{\mathbf{e}}(\pmb{\theta}) = \frac{\sum_{i=1}^{N_s} W(\vert\pmb{\theta}-\pmb{\theta}_i\vert)w(\pmb{\theta}_i)[\mathbf{e}^{obs}(\pmb{\theta}_i)-c(\pmb{\theta}_i)]}{\sum_{i=1}^{N_s}W(\vert\pmb{\theta}-\pmb{\theta}_i\vert)w(\pmb{\theta}_i)[1+m(\pmb{\theta})]}
\end{equation} 
\begin{equation}
\label{gausskernel}
W_{\theta_G}(\pmb{\theta}) = \frac{1}{2\pi\theta_G^2}\exp{\left(-\frac{\pmb{\theta}^2}{2\theta_G^2}\right)}
\end{equation}
%
where the smoothing kernel $W_{\theta_G}$ has been varied choosing from the set $(0.5,1.0,1.8,3.5,5.3,8.9)\,$arcmin; the multiplicative and additive corrections $m,c$ related the observed and true ellipticities of the galaxies in the catalogue
\begin{equation}
\mathbf{e}^{obs} = (1+m)\mathbf{e}^{true} + c
\end{equation}
%
Using the ellipticity grid $\bar{\mathbf{e}}(\pmb{\theta})$ as an estimator for the cosmic shear $\gamma^{1,2}(\pmb{\theta})$, we can perform a non--local Kaiser--Squires inversion to recover the convergence $\kappa(\pmb{\theta})$ from the $E$--mode of the shear field
%
\begin{equation}
\kappa(\mathbf{l}) = \left(\frac{l_1^2-l_2^2}{l_1^2+l_2^2}\right)\gamma^1(\mathbf{l}) + 2\frac{l_1l_2}{l_1^2+l_2^2}\gamma^2(\mathbf{l})
\end{equation}
%
The CFHTLens catalogues contain masked regions (mainly due to bright stars and incorrect PSF subtraction); these regions with low galaxy number density can induce large errors in the cosmological parameter inferences, hence they need to be masked out. We first create grided maps of the same size and resolution as the $\kappa$ maps, but with each pixel containing the number of galaxies ($n_{gal}$) falling within its window. We then smooth this galaxy surface density map with the same Gaussian window function as equation (\ref{gausskernel}) and we remove regions where $n_{gal} < 5 \,\mathrm{arcmin}^{âˆ’2}$ (see \citep{CFHTMasato}); for a more throughout description of our data reduction procedure, we refer the reader to our companion paper \citep{Companion}. 

\subsection{Simulation design}
In this paragraph we give a description of the method we used to sample the parameter space in our simulation effort. We wish to investigate the non--linear dependency of cosmological probes (in this work Minkowski Functionals and Moments of the $\kappa$ field) on the parameter triplet $\mathbf{p}=(\Omega_m,w,\sigma_8)$, while keeping fixed the other relevant parameters to $(h,\Omega_b,n_s)$ to their fiducial values (0.7,0.046,0.96). We sampled the $D$--dimensional ($D=3$ in this case) parameter space using an irregularly spaced grid, designed with a method similar to \citep{coyote2}. We limit the parameter sampling in a box of corners $\Omega_m\in[0.07,1],\,w\in[-3.0,0],\,\sigma_8\in[0.1,1.5]$ and we map this sampling box $\Pi$ into an hypercube of unit side; we want to contruct an irregularly spaced grid consisting of $N$ points $\mathbf{x}_i\in[0,1]^D$. Let a \textit{design} $\mathcal{D}$ be the set of this irregularly spaced $N$ points: we wish to find an optimal design, in which the points are spread as uniformly as possible inside the box. Following \citep{coyote2}, we choose our optimal design as the minimum of the cost function

\begin{equation}
\label{costfunction}
d(\mathcal{D}) = \frac{2D^{1/2}}{N(N-1)}\sum_{i<j}^N\frac{1}{\vert\mathbf{x}_i-\mathbf{x}_j\vert}
\end{equation} 
%
This problem is mathematically equivalent to the minimization of the Coulomb potential energy of $N$ unit charges in a unit box, which will make sure that the charges are as evenly spread as possible throughout the confining volume. Finding the optimal design $\mathcal{D}_m$ that minimized (\ref{costfunction}) can be computationally very demanding, and hence we decided to use a simplified approach that, although approximate, serves our purposes for the grid design. We use an iterative procedure:
\begin{enumerate}
\item We start from the diagonal design $\mathcal{D}_0$: $x_i^d\equiv i/(N-1)$
\item We shuffle the coordinates of the particles in each dimension independently $x_i^d = \mathcal{P}_d\left(\frac{1}{N-1},\frac{2}{N-1},...,1\right)$ where $\mathcal{P}_1,...,\mathcal{P}_D$ are random independent permutations of $(1,2,...,N)$
\item We pick a random particle pair $(i,j)$ and a random coordinate $d\in\{1,...,D\}$ and swap $x_i^d\leftrightarrow x_j^d$
\item We compute the new cost function, if this is less than the previous step, we keep the exchange, otherwise we revert the coordinate swap
\item We repeat steps 3 and 4 until the relative cost function change is less than a chosen accuracy parameter $\epsilon$ 
\end{enumerate}
%
We found that for $N=91$ grid points, order of $10^5$ iterations are sufficient to reach an accuracy of $\epsilon\sim10^{-4}$; once the optimal design $\mathcal{D}_m$ has been found, we can invert the mapping $\Pi\rightarrow[0,1]^3$ to find our simulation parameter sampling $\mathbf{p}_s$, which we show in Table \ref{designtable} and Figure \ref{designfig}.
%
\begin{table*}
\begin{tabular}{c|ccc||c|ccc||c|ccc||c|ccc}
$N$ & $\Omega_m$ & $w$ & $\sigma_8$ & $N$ & $\Omega_m$ & $w$ & $\sigma_8$ & $N$ & $\Omega_m$ & $w$ & $\sigma_8$ & $N$ & $\Omega_m$ & $w$ & $\sigma_8$ \\ \hline
1 & 0.136 & -2.484 & 1.034 & 26 & 0.380 & -2.424 & 0.199 & 51 & 0.615 & -1.668 & 0.185 & 76 & 0.849 & -0.183 & 0.821 \\
2 & 0.145 & -2.211 & 1.303 & 27 & 0.389 & -0.939 & 0.454 & 52 & 0.624 & -2.757 & 0.327 & 77 & 0.859 & -1.182 & 1.415 \\
3 & 0.155 & -0.393 & 0.652 & 28 & 0.399 & -1.938 & 1.500 & 53 & 0.634 & -1.575 & 0.976 & 78 & 0.869 & -2.031 & 0.227 \\
4 & 0.164 & -2.181 & 0.313 & 29 & 0.409 & -2.940 & 0.737 & 54 & 0.643 & -2.454 & 1.444 & 79 & 0.878 & -2.697 & 0.524 \\
5 & 0.173 & -0.423 & 1.231 & 30 & 0.418 & -1.758 & 0.383 & 55 & 0.652 & -1.029 & 1.458 & 80 & 0.887 & -0.363 & 0.439 \\
6 & 0.183 & -0.909 & 0.269 & 31 & 0.427 & -2.910 & 0.411 & 56 & 0.661 & -0.486 & 0.892 & 81 & 0.897 & -0.999 & 0.468 \\
7 & 0.192 & -1.605 & 1.401 & 32 & 0.436 & -0.060 & 0.878 & 57 & 0.671 & -2.364 & 0.793 & 82 & 0.906 & -1.698 & 1.273 \\
8 & 0.201 & -2.787 & 0.807 & 33 & 0.446 & -1.212 & 1.486 & 58 & 0.681 & -2.970 & 0.610 & 83 & 0.915 & -2.544 & 1.175 \\
9 & 0.211 & -0.333 & 0.341 & 34 & 0.455 & -2.637 & 1.373 & 59 & 0.690 & -1.332 & 0.482 & 84 & 0.925 & -0.636 & 1.259 \\
10 & 0.221 & -1.485 & 0.666 & 35 & 0.464 & -2.121 & 0.906 & 60 & 0.700 & -0.273 & 0.283 & 85 & 0.943 & -2.394 & 0.835 \\
11 & 0.239 & -1.848 & 0.962 & 36 & 0.474 & -1.302 & 0.114 & 61 & 0.709 & -2.061 & 0.425 & 86 & 0.953 & -1.545 & 0.355 \\
12 & 0.249 & -2.727 & 0.369 & 37 & 0.483 & -1.515 & 0.680 & 62 & 0.718 & -1.728 & 1.472 & 87 & 0.963 & -2.151 & 0.510 \\
13 & 0.258 & -1.395 & 0.241 & 38 & 0.493 & -0.243 & 0.297 & 63 & 0.728 & -0.120 & 0.596 & 88 & 0.972 & -0.666 & 0.694 \\
14 & 0.267 & -2.667 & 1.317 & 39 & 0.502 & -1.152 & 1.189 & 64 & 0.737 & -2.847 & 1.203 & 89 & 0.981 & -1.242 & 1.048 \\
15 & 0.276 & -0.849 & 1.429 & 40 & 0.512 & -0.819 & 0.849 & 65 & 0.746 & -0.090 & 1.118 & 90 & 0.991 & -1.908 & 1.020 \\
16 & 0.286 & -1.272 & 1.104 & 41 & 0.521 & -2.334 & 0.538 & 66 & 0.755 & -0.456 & 1.359 & 91 & 1.000 & -1.425 & 0.708 \\
17 & 0.295 & -1.878 & 0.100 & 42 & 0.530 & 0.000 & 0.624 & 67 & 0.765 & -2.091 & 1.076 & -- & -- & -- & -- \\
18 & 0.305 & -0.879 & 0.765 & 43 & 0.540 & -0.030 & 1.161 & 68 & 0.775 & -1.122 & 1.132 & -- & -- & -- & -- \\
19 & 0.315 & -2.241 & 0.638 & 44 & 0.549 & -1.818 & 1.287 & 69 & 0.784 & -1.062 & 0.779 & -- & -- & -- & -- \\
20 & 0.324 & -2.001 & 1.217 & 45 & 0.558 & -2.577 & 1.146 & 70 & 0.794 & -1.365 & 0.156 & -- & -- & -- & -- \\
21 & 0.333 & -0.213 & 0.552 & 46 & 0.568 & -0.516 & 1.331 & 71 & 0.803 & -2.607 & 0.255 & -- & -- & -- & -- \\
22 & 0.342 & -2.817 & 1.062 & 47 & 0.577 & -3.000 & 0.948 & 72 & 0.812 & -1.788 & 0.722 & -- & -- & -- & -- \\
23 & 0.352 & -0.576 & 1.090 & 48 & 0.587 & -2.304 & 0.128 & 73 & 0.821 & -2.880 & 0.863 & -- & -- & -- & -- \\
24 & 0.361 & -0.606 & 0.171 & 49 & 0.596 & -0.696 & 0.496 & 74 & 0.831 & -0.759 & 0.213 & -- & -- & -- & -- \\
25 & 0.370 & -0.303 & 1.345 & 50 & 0.606 & -0.789 & 0.142 & 75 & 0.840 & -2.274 & 1.387 & -- & -- & -- & -- \\
\end{tabular}
\caption{List of the CFHTemu1 grid points in parameter space}
\label{designtable}
\end{table*}
%
\begin{figure*}
\begin{center}
\includegraphics[scale=0.4]{Figures/design.eps}
\caption{$(\Omega_m,w)$ and $(w,\sigma_8)$ projections of our the simulation design; the blue points correspond to the CFHTemu1 simulation set, which consists of one $N$--body simulation per point, while the red point corresponds to the CFHTcov simulation set, which is based on 50 independent $N$--body simulations}
\label{designfig}
\end{center}
\end{figure*}
%
For each parameter point on the grid $\mathbf{p}_s$ we run one $N$--body simulation and perform ray tracing through it, as described in \S~\ref{raysim}, to simulate CFHTLens shear catalogs; this set of simulations will be called CFHTemu1 throughout the rest of this work. Additionally, we run 50 independent $N$--body simulations with a \textit{fiducial} parameter choice $\mathbf{p}_0=(0.26,-1.0,0.8)$ for the purpose of measuring accurately the covariance matrices which will serve the parameter inferences as in \S-\ref{cosmostats}; this set of simulations will be called CFHTcov throughout the rest of this work.    

\subsection{Ray Tracing Simulations}
\label{raysim}
The goal of this paragraph is to give an outline of our simulation pipeline; the fluctuations in the dark matter density field between a source at redshift $z$ and an observer located on Earth will cause small deflections to the trajectories of light rays travelling from the source to the observer. The fluctuations in the dark matter field are described by their gravitational potential $\Phi(\mathbf{x},z)=\Phi(\mathbf{x}_\perp,w(z))$, where we can trade the physical coordinates $\mathrm{x}$ with the comoving distance from the observer $w$ (not to be confused with the weight factor in \S\ref{cfhtdatareduction}) and two transverse coordinates $\mathbf{x}_\perp=w\pmb{\beta}$ using the flat sky approximation. Here $\pmb{\beta}$ refers to the angular coordinate on the sky of a physical point $\mathbf{x}$, as seen from the observer. We estimate the dark matter gravitational potential running $N$--body simulations (with $N=512^3$) with the public code Gadget2 \citep{Gadget2}, using a comoving box size of $240h^{-1}$Mpc. Using a similar procedure as in \citep{RayTracingJain,RayTracingHartlap}, the equation that governs the light ray deflections can be written in the form
\begin{equation}
\label{raytrajectory}
\frac{d^2\mathbf{x}(w)}{dw^2} = -\frac{2}{c^2}\nabla_{\mathbf{x}_\perp}\Phi(\mathbf{x}_\perp(w),w)
\end{equation}
%
where $\mathbf{x}(w)$ is the trajectory of a single light ray, which we visualize schematically in Figure \ref{rayscheme}. 
%
\begin{figure*}
\begin{center}
\includegraphics[scale=0.4]{Figures/rayscheme.eps}
\end{center}
\caption{Schematics of ray tracing with the lensing potential boosted by a factor of 50 for visualization purposes}
\label{rayscheme}
\end{figure*}
%
Suppose that a light ray reaches the observer at an angular position $\pmb{\theta}$ on the sky: we want to know where this light ray originated, knowing it comes from a redshift $z_s$. To answer this question we need to integrate equation (\ref{raytrajectory}) with the initial conditions $\pmb{\beta}(0;\pmb{\theta})=\pmb{\theta}$, $\dot{\pmb{\beta}}(0;\pmb{\theta})=0$ up to a distance $w_s=w(z_s)$ to obtain the source angular position $\pmb{\beta}(w_s;\pmb{\theta})$; for the light ray trajectory solver, based on equation (\ref{raytrajectory}), we use our proprietary implementation Inspector Gadget. Once we know the details of the light ray trajectories, we can easily infer the weak lensing interesting quantities by taking the angular derivatives of the ray deflections $A(w_s;\pmb{\theta}) = \partial \pmb{\beta}(w_s;\pmb{\theta})/\partial\pmb{\theta}$ and performing the usual spin decomposition to infer the convergence $\kappa$ and the shear components $(\gamma^1,\gamma^2)$
%
\begin{equation}
A(w_s;\pmb{\theta}) = (1-\kappa(w_s;\pmb{\theta}))\pmb{I} - \gamma^1(w_s;\pmb{\theta})\sigma^3 - \gamma^2(w_s;\pmb{\theta})\sigma^1
\end{equation}  
%
where $\pmb{I}$ is the $2\times2$ identity and $\sigma^{1,3}$ are the first and third Pauli matrices. $\kappa$ is related to the source apparent magnification, while $(\gamma^1,\gamma^2)$ are related to the source apparent ellipticity, as seen from the observer. Given a source with intrinsic ellipticity $\mathbf{e}_s=e^1_s + ie^2_s$, its observed ellipticity as seen from an observer will be modified by the cosmic shear $\pmb{\gamma}=\gamma^1 + i\gamma^2$ following
%
\begin{equation}
\mathbf{e} = 
\begin{cases}
\frac{\mathbf{e}_s+\mathbf{g}}{1+\mathbf{g}^*\mathbf{e}_s} \,\,\,\,\,\,\,\, \vert \mathbf{g}\vert \leq 1 \\ \\
\frac{1+\mathbf{ge}_s^*}{\mathbf{e}_s^* + \mathbf{g}^*} \,\,\,\,\,\,\,\, \vert \mathbf{g}\vert > 1
\end{cases}
\end{equation}
%
where $\mathbf{g} = \pmb{\gamma}/1-\kappa$ is the reduced shear. For each simulated galaxy, we assign an intrinsic elliptic- ity by rotating the observed ellipticity for that galaxy by a random angle on the sky, while conserving its magnitude $\vert\mathbf{e}\vert$. To be consistent with the CFHTLenS analysis, we adopt the weak lensing limit ($\vert\pmb{\gamma}\vert\ll1,\kappa\ll1$),hence $\mathbf{g}\approx\pmb{\gamma}$ and $\mathbf{e}\approx \mathbf{e}_s+\pmb{\gamma}$. We also add the multiplicative shear corrections by replacing $\pmb{\gamma}$ with $(1+m)\pmb{\gamma}$; like for the CFHTLens data, we proceed in constructing the simulated $\kappa$ maps as explained in \S\ref{cfhtdatareduction}. These final simulation products are then processed together with the $\kappa$ maps obtained from the data to calculate the confidence intervals on the parameter triplet $(\Omega_m,w,\sigma_8)$.

%%%%%%%%%%%%%%%%%%%%%%%%%% METHODS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Statistical methods}
The goal of this section is to describe the framework in which we combine the CFHT data and our simulations in order to derive the constraints on the cosmological parameter triplet $(\Omega_m,w,\sigma_8)$; we measure a set of statistical descriptors from the data and the simulations, which will then be compared in a bayesian fashion in order to compute parameter confidence intervals.

\subsection{Descriptors}
The statistical descriptors we consider on this work are the Minkowski Functionals (MFs) and the low order moments (LM) of the convergence field. The three MFs $(V_0,V_1,V_2)$ are topological descriptors of the convergence random field $\kappa(\pmb{\theta})$, which probe respectively the area, perimeter and genus characteristic of the $\kappa$ excursion sets $\Sigma_{\kappa_0}$, defined as $\Sigma_{\kappa_0}=\{\kappa>\kappa_0\}$. Following \citep{Petri2013,MinkJan} we use the following local estimators to measure the MFs from the $\kappa$ images. 
%
\begin{equation*}
\label{v0meas}
V_0(\kappa_0)=\frac{1}{A}\int_A\Theta(\kappa(\pmb{\theta})-\kappa_0)d\pmb{\theta},
\end{equation*}
\begin{equation}
\label{v1meas}
V_1(\kappa_0)=\frac{1}{4A}\int_A\delta(\kappa(\pmb{\theta})-\kappa_0)\sqrt{\kappa_x^2+\kappa_y^2}d\pmb{\theta},
\end{equation}
\begin{equation*}
\label{v2meas}
V_2(\kappa_0)=\frac{1}{2\pi A}\int_A\delta(\kappa(\pmb{\theta})-\kappa_0)\frac{2\kappa_x\kappa_y\kappa_{xy}-\kappa_x^2\kappa_{yy}-\kappa_y^2\kappa_{xx}}{\kappa_x^2+\kappa_y^2}d\pmb{\theta}.
\end{equation*}
%
Where $A$ is the total area of the fields of view we have been using and the notation $\kappa_{x,y}$ indicates gradients of the $\kappa$ field, which we evaluate using finite differences. The first Minkowski functional, $V_0$, is equivalent to the cumulative one--point PDF of the $\kappa$ field, while $V_1,V_2$ are sensitive to the correlations between nearby pixels. In addition to these topological descriptors, we consider a set of low order moments (LM) of the convergence field (two quadratic, three cubic and four quartic), which are defined in the following way
%
\begin{equation}
\begin{matrix}
\mathrm{LM_2}: \sigma_{0,1}^2 = \langle\kappa^2\rangle,\langle\vert\nabla\kappa\vert^2\rangle, \\ \\
\mathrm{LM_3}: S_{0,1,2} = \langle\kappa^3\rangle,\langle\kappa\vert\nabla\kappa\vert^2\rangle,\langle\kappa^2\nabla^2\kappa\rangle, \\ \\
\mathrm{LM_4}: K_{0,1,2,3} = \langle\kappa^4\rangle,\langle\kappa^2\vert\nabla\kappa\vert^2\rangle,\langle\kappa^3\nabla^2\kappa\rangle,\langle\vert\nabla\kappa\vert^4\rangle.
\end{matrix}
\end{equation}
%
If the $\kappa$ field was Gaussian, one could express all the Minkowski Functionals in terms of the LM2 moments, as expected from the fact that, for a Gaussian field, the only meaningful statistics are the quadratic ones. In reality, weak lensing convergence fields, as the CFHTLens ones, are non--Gaussian and the MF and LM descriptors are in principle equivalent. \citep{Munshi12,Matsubara10} studied a perturbative expansion of the MF descriptors in powers of the field standard deviation $\sigma_0$, which, when truncated at order $O(\sigma_0^2)$, can be expressed completely in terms of the LM up to quartic order. Such perturbative series, however, have been shown not to converge in \citep{Petri2013} unless the weak lensing fields are smoothed with windows of size comparable to $\sim 15^\prime$. Because of this, throughout this work, we treat MF and LM as independent statistical descriptors. 

\subsection{Cosmological parameter inferences}
\label{cosmostats}
In this paragraph we give a brief outline of the statistical framework we adopted for computing the cosmological parameter confidence levels from the CFHTLens observations; we make use of the MF and LM statistical descriptors outlined in the previous paragraph. We refer to $M_i^r(\mathbf{p})$ as the measured descriptor from a realization $r$ of one of our simulations with a choice of cosmological parameters $\mathbf{p}$, and to $D_i$ as the measured descriptor from the CFHTLens data. In this notation, $i$ is an index that refers to the particular bin on which the descriptor is evaluated (for example $i$ can range from 0 to 9 for the LM statistic and from 0 to $N_b-1$ for a Minkowski Functional measured on $N_b$ different excursion sets). Once we make an assumption for the data likelihood $\mathcal{L}_d(D_i\vert \mathbf{p})$ and for the parameter priors $\Pi(\mathbf{p})$, we can use the Bayes theorem to compute the parameter likelihood $\mathcal{L}_p$ as follows

\begin{equation}
\label{parameterlikelihood}
\mathcal{L}_p(\mathbf{p}\vert D_i) = \frac{\mathcal{L}_d(D_i\vert \mathbf{p})\Pi(\mathbf{p})}{N_{\mathcal{L}}}
\end{equation}
%
where $N_{\mathcal{L}}$ is a $\mathbf{p}$--independent constant that ensures the proper normalization for $\mathcal{L}_p$; we make the usual assumption that the data likelihood $\mathcal{L}_d(D_i\vert \mathbf{p})$ is a Gaussian

\begin{equation}
\label{datalikelihood}
\begin{matrix}
\mathcal{L}_d(D_i\vert \mathbf{p}) = ((2\pi)^{N_b}\det{\mathbf{C}})^{-1/2} e^{-\frac{1}{2}\chi^2(D_i\vert \mathbf{p})} \\ \\
\chi^2(D_i\vert \mathbf{p}) = \mathbf{(D - M(p))C^{-1}(D-M(p))}
\end{matrix}
\end{equation} 
%
The simulated descriptors $\mathbf{M(p)}$ are measured from an average over realizations
\begin{equation}
M_i(\mathbf{p}) = \frac{1}{R}\sum_{r=1}^R M_i^r 
\end{equation}
%
and the covariance matrix 
\begin{equation}
C_{ij} = \frac{1}{R-1} \sum_{r=1}^R [M_i^r(\mathbf{p}_0)-M_i(\mathbf{p}_0)][M_j^r(\mathbf{p}_0)-M_j(\mathbf{p}_0)]
\end{equation}
%
is measured from a simulation set based on 50 independent $N$--body simulations with parameters $\mathbf{p}_0=(0.26,-1.0,0.8)$ and is assumed to be model--independent; because of this the normalization constant in (\ref{datalikelihood}) is also model--independent. When computing parameter constraints from CFHTLens weak lensing data alone, we make a flat prior assumption for $\Pi(\mathbf{p})$. Parameter inferences are made estimating the location of the maximum of the parameter likelihood in (\ref{parameterlikelihood}), which we call $\mathbf{p}_{ML}(D_i)$ as well as its confidence contours. A $N\sigma$--confidence contour of $\mathcal{L}_p(\mathbf{p}\vert D_i)$ is defined to be the subset of points in parameter space on which the likelihood has a constant value $c_N$ and 
\begin{equation}
\int_{\mathcal{L}>c_N} \mathcal{L}_p(\mathbf{p}\vert D_i) d\mathbf{p} = \frac{1}{\sqrt{2\pi}}\int_{-N}^N dx e^{-x^2/2}
\end{equation}
%
Given the low dimensionality of the parameter space we consider $(N_p=3)$ we are able to evaluate the parameter likelihood (\ref{parameterlikelihood}) on a finely spaced $100\times100\times100$ mesh within the prior window $\Pi(\mathbf{p})$, and hence we are able to evaluate the likelihood maximum $\mathbf{p}_{ML}(D_i)$ and the contour levels $c_N$ directly without the need to use more sophisticated MCMC methods. We know how to evaluate the data likelihood (\ref{datalikelihood}) on the simulation grid $\mathbf{p}_s$, but more work needs to be done to interpolate $M_(\mathbf{p})$ at an arbitrary intermediate point; we decided to use a Radial Basis Function (RBF) interpolation scheme. We approximate the model descriptor as
\begin{equation}
M(\mathbf{p}) = \sum_{s=1}^N \lambda_s\phi(\vert\mathbf{p}-\mathbf{p}_s\vert)
\end{equation}
%
where $\phi$ has been chosen as a multiquadric function $\phi(r)=\sqrt{1+(r/r_0)^2}$ with $r_0$ chosen as the mean euclidean distance between the points in the simulated grid $\mathbf{p}_s$. The constant coefficients $\lambda_s$ can be determined imposing the $N$ constraints $M(\mathbf{p}=\mathbf{p}_s)=M(\mathbf{p_s})$, which enforce the fact that the interpolation should be exact at the simulated points. The interpolation computations are conveniently performed using the Scipy library \citep{scipy} 

%%%%%%%%%%%%%%%%%%%%%%%%%% RESULTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%% DISCUSSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%% CONCLUSIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}

%%%%%%%%%%%%%%%%%%%%%%%%%% ACKNOWLEDGMENTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 

\section*{Acknowledgements}
We thank the Stampede cluster who saved our day

\bibliography{ref}
\label{lastpage}
\end{document}
